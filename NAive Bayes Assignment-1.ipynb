{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem is a mathematical formula used to determine the **conditional probability of an event**, based on prior knowledge of conditions that might be related to that event ¹. It is named after Reverend Thomas Bayes, an 18th-century statistician and Presbyterian minister ¹. \n",
    "\n",
    "The general statement of Bayes’ theorem is: \n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where, \n",
    "\n",
    "- $P(A|B)$ is the probability of event A when event B happens.\n",
    "- $P(B|A)$ is the probability of event B when A happens.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of events A and B, respectively.\n",
    "\n",
    "Bayes' theorem is used in various fields such as statistics, machine learning, artificial intelligence, and more. It is particularly useful in situations where the probability of occurrence of a particular event is calculated based on other conditions which are also called conditional probability ¹. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where, \n",
    "\n",
    "- $P(A|B)$ is the probability of event A when event B happens.\n",
    "- $P(B|A)$ is the probability of event B when A happens.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of events A and B, respectively ¹."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in various fields such as **medical testing**, **machine learning**, **artificial intelligence**, and more ¹. It is particularly useful in situations where the probability of occurrence of a particular event is calculated based on other conditions which are also called conditional probability ¹. \n",
    "\n",
    "Here are some examples of how Bayes' theorem is used in practice:\n",
    "\n",
    "- **Medical diagnosis**: Bayes' theorem is used to calculate the probability of a patient having a particular disease based on the results of a medical test ¹. For example, if a patient tests positive for a particular disease, Bayes' theorem can be used to calculate the probability of the patient actually having the disease ¹.\n",
    "\n",
    "- **Spam filtering**: Bayes' theorem is used in spam filtering to classify emails as spam or not spam ¹. The probability of an email being spam is calculated based on the presence of certain keywords or phrases in the email ¹.\n",
    "\n",
    "- **Weather forecasting**: Bayes' theorem is used in weather forecasting to calculate the probability of certain weather conditions occurring based on past weather data ¹.\n",
    "\n",
    "- **Stock market analysis**: Bayes' theorem is used in stock market analysis to calculate the probability of a particular stock performing well based on past performance data ¹.\n",
    "\n",
    "- **Machine learning**: Bayes' theorem is used in machine learning algorithms such as Naive Bayes classifier, which is used for text classification, spam filtering, and more ¹."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem is a formula that describes how to update the probabilities of hypotheses when given evidence ¹. It follows simply from the axioms of conditional probability, but can be used to powerfully reason about a wide range of problems involving belief updates ³. \n",
    "\n",
    "In fact, Bayes' theorem is derived from conditional probability ¹. Conditional probability is the probability of an event occurring given that another event has occurred ¹. Bayes' theorem is used to update the probability of a hypothesis based on new evidence or data ¹. It allows us to calculate the probability of a hypothesis given some observed evidence ¹. \n",
    "\n",
    "The general statement of Bayes’ theorem is: \n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where, \n",
    "\n",
    "- $P(A|B)$ is the probability of event A when event B happens.\n",
    "- $P(B|A)$ is the probability of event B when A happens.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of events A and B, respectively.\n",
    "\n",
    "Bayes' theorem is used in various fields such as **medical testing**, **machine learning**, **artificial intelligence**, and more ¹. It is particularly useful in situations where the probability of occurrence of a particular event is calculated based on other conditions which are also called conditional probability ¹. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right type of Naive Bayes classifier depends on the **nature of the data** and the **problem at hand** ¹. Here are some general guidelines to help you choose the right type of Naive Bayes classifier:\n",
    "\n",
    "- **Bernoulli Naive Bayes**: This classifier is used when the features are **binary** (i.e., 0 or 1) ¹. It is commonly used in text classification problems where the presence or absence of a word is used as a feature ¹.\n",
    "\n",
    "- **Multinomial Naive Bayes**: This classifier is used when the features are **discrete** (i.e., counts) ¹. It is commonly used in text classification problems where the frequency of a word is used as a feature ¹.\n",
    "\n",
    "- **Gaussian Naive Bayes**: This classifier is used when the features are **continuous** (i.e., real-valued) ¹. It is commonly used in problems where the features are continuous variables such as height, weight, etc. ¹.\n",
    "\n",
    "In practice, it is often useful to try out different types of Naive Bayes classifiers and compare their performance on the given problem ¹. You can use cross-validation techniques to evaluate the performance of different classifiers ¹. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "\n",
    "A 3 3 4 4 3 3 3\n",
    "\n",
    "B 2 2 1 2 2 2 3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the dataset with two features, X1 and X2, and two possible classes, A and B, we want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "| **Class** | **X1=1** | **X1=2** | **X1=3** | **X2=1** | **X2=2** | **X2=3** | **X2=4** |\n",
    "|-----------|----------|----------|----------|----------|----------|----------|----------|\n",
    "| A         | 3        | 3        | 4        | 4        | 3        | 3        | 3        |\n",
    "| B         | 2        | 2        | 1        | 2        | 2        | 2        | 3        |\n",
    "\n",
    "Assuming equal prior probabilities for each class, we can calculate the probability of the new instance belonging to class A and class B using Bayes' theorem. \n",
    "\n",
    "Let's first calculate the probability of the new instance belonging to class A:\n",
    "\n",
    "$$P(A|X1=3,X2=4) = \\frac{P(X1=3,X2=4|A)P(A)}{P(X1=3,X2=4)}$$\n",
    "\n",
    "where, \n",
    "\n",
    "- $P(A|X1=3,X2=4)$ is the probability of the new instance belonging to class A given the values of X1 and X2.\n",
    "- $P(X1=3,X2=4|A)$ is the probability of observing the values of X1 and X2 given that the new instance belongs to class A.\n",
    "- $P(A)$ is the prior probability of class A.\n",
    "- $P(X1=3,X2=4)$ is the probability of observing the values of X1 and X2.\n",
    "\n",
    "Using the Naive Bayes assumption that the features are independent, we can simplify the above equation as follows:\n",
    "\n",
    "$$P(A|X1=3,X2=4) = \\frac{P(X1=3|A)P(X2=4|A)P(A)}{P(X1=3,X2=4)}$$\n",
    "\n",
    "Similarly, we can calculate the probability of the new instance belonging to class B:\n",
    "\n",
    "$$P(B|X1=3,X2=4) = \\frac{P(X1=3|B)P(X2=4|B)P(B)}{P(X1=3,X2=4)}$$\n",
    "\n",
    "where, \n",
    "\n",
    "- $P(B|X1=3,X2=4)$ is the probability of the new instance belonging to class B given the values of X1 and X2.\n",
    "- $P(X1=3|B)$ is the probability of observing the value of X1 given that the new instance belongs to class B.\n",
    "- $P(X2=4|B)$ is the probability of observing the value of X2 given that the new instance belongs to class B.\n",
    "- $P(B)$ is the prior probability of class B.\n",
    "- $P(X1=3,X2=4)$ is the probability of observing the values of X1 and X2.\n",
    "\n",
    "Since we are assuming equal prior probabilities for each class, we have:\n",
    "\n",
    "$$P(A) = P(B) = \\frac{1}{2}$$\n",
    "\n",
    "We can calculate the probabilities of observing the values of X1 and X2 given that the new instance belongs to class A and class B from the table:\n",
    "\n",
    "$$P(X1=3|A) = \\frac{4}{10} = 0.4$$\n",
    "$$P(X2=4|A) = \\frac{3}{10} = 0.3$$\n",
    "$$P(X1=3|B) = \\frac{1}{7} \\approx 0.143$$\n",
    "$$P(X2=4|B) = \\frac{1}{7} \\approx 0.143$$\n",
    "\n",
    "We can calculate the probability of observing the values of X1 and X2 as follows:\n",
    "\n",
    "$$P(X1=3,X2=4) = P(X1=3,X2=4|A)P(A) + P(X1=3,X2=4|B)P(B)$$\n",
    "$$P(X1=3,X2=4) = (0.4)(0.3)\\left(\\frac{1}{2}\\right) + (0.143)(0.143)\\left(\\frac{1}{2}\\right) \\approx 0.055$$\n",
    "\n",
    "Finally, we can calculate the probabilities of the new instance belonging to class A and class B:\n",
    "\n",
    "$$P(A|X1=3,X2=4) = \\frac{(0.4)(0.3)\\left(\\frac{1}{2}\\right)}{0.055} \\approx 0."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
